{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgymnasium\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m solve_continuous_are\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from scipy.linalg import solve_continuous_are\n",
    "\n",
    "# Define the dynamics and cost functions\n",
    "def dynamics(x, u):\n",
    "    \"\"\"\n",
    "    Dynamics of the Continuous Mountain Car environment.\n",
    "    x: state vector [position, velocity]\n",
    "    u: control input [force]\n",
    "    \"\"\"\n",
    "    position, velocity = x\n",
    "    force = np.clip(u, -1.0, 1.0)  # Clip force to valid range\n",
    "    new_velocity = velocity + 0.001 * force - 0.0025 * np.cos(3 * position)\n",
    "    new_position = position + new_velocity\n",
    "    new_velocity = np.clip(new_velocity, -0.07, 0.07)  # Clip velocity to valid range\n",
    "    return np.array([new_position, new_velocity])\n",
    "\n",
    "def cost(x, u):\n",
    "    \"\"\"\n",
    "    Cost function for the Continuous Mountain Car problem.\n",
    "    x: state vector [position, velocity]\n",
    "    u: control input [force]\n",
    "    \"\"\"\n",
    "    position, velocity = x\n",
    "    target_position = 0.45  # Target position (top of the hill)\n",
    "    return (position - target_position) ** 2 + 0.1 * (u ** 2)  # Quadratic cost\n",
    "\n",
    "def linearize_dynamics(x, u):\n",
    "    \"\"\"\n",
    "    Linearize the dynamics around the current state and control.\n",
    "    Returns A (state Jacobian) and B (control Jacobian).\n",
    "    \"\"\"\n",
    "    A = np.array([[1, 0.001], [0.0025 * 3 * np.sin(3 * x[0]), 1]])\n",
    "    B = np.array([[0], [0.001]])\n",
    "    return A, B\n",
    "\n",
    "def iLQR(env, max_iter=100, tol=1e-6):\n",
    "    \"\"\"\n",
    "    Iterative Linear Quadratic Regulator (iLQR) algorithm.\n",
    "    \"\"\"\n",
    "    # Initialize state and control\n",
    "    state = env.reset()[0]\n",
    "    u = np.zeros(1)  # Initial control input\n",
    "\n",
    "    # Define cost matrices\n",
    "    Q = np.diag([1.0, 0.1])  # State cost\n",
    "    R = np.array([[0.1]])  # Control cost\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        # Linearize dynamics\n",
    "        A, B = linearize_dynamics(state, u)\n",
    "\n",
    "        # Solve Riccati equation for the value function\n",
    "        P = solve_continuous_are(A, B, Q, R)\n",
    "\n",
    "        # Compute optimal control\n",
    "        K = -np.linalg.inv(R + B.T @ P @ B) @ B.T @ P @ A\n",
    "        u_new = K @ state\n",
    "\n",
    "        # Check for convergence\n",
    "        if np.linalg.norm(u_new - u) < tol:\n",
    "            break\n",
    "\n",
    "        # Update control\n",
    "        u = u_new\n",
    "\n",
    "        # Simulate one step\n",
    "        state = dynamics(state, u)\n",
    "\n",
    "    return u\n",
    "\n",
    "# Main function to run the iLQR algorithm\n",
    "def main():\n",
    "    env = gym.make(\"MountainCarContinuous-v0\")\n",
    "    optimal_control = iLQR(env)\n",
    "    print(\"Optimal Control Input:\", optimal_control)\n",
    "\n",
    "    # Test the optimal control\n",
    "    state = env.reset()[0]\n",
    "    total_cost = 0\n",
    "    for _ in range(1000):\n",
    "        env.render()\n",
    "        state = dynamics(state, optimal_control)\n",
    "        total_cost += cost(state, optimal_control)\n",
    "        if state[0] >= 0.45:  # Check if the car reached the goal\n",
    "            print(\"Goal reached!\")\n",
    "            break\n",
    "    print(\"Total Cost:\", total_cost)\n",
    "    env.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
